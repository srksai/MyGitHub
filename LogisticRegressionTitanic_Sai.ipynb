{
 "metadata": {
  "name": "",
  "signature": "sha256:8e52852dd3dc74c2564c67aa05215d440077d11c0f3cef45037755e812154b40"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lecture 6 Lab - Predicting Survival on the Titanic using Logistic Regression\n",
      "\n",
      "\n",
      "###Data Prep\n",
      "First, I will start with some data prep to get my data ready to be used in a model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "%pylab inline\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 665
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reading the data from the disk into memory\n",
      "df = pd.read_csv(\"train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 666
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 667,
       "text": [
        "(891, 12)"
       ]
      }
     ],
     "prompt_number": 667
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in list(df):\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PassengerId\n",
        "Survived\n",
        "Pclass\n",
        "Name\n",
        "Sex\n",
        "Age\n",
        "SibSp\n",
        "Parch\n",
        "Ticket\n",
        "Fare\n",
        "Cabin\n",
        "Embarked\n"
       ]
      }
     ],
     "prompt_number": 668
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Looking at the columns above, I dont think we need to use all of these for our regression as some of them have tons of data missing. So, lets clean up. So, the strategy with dealing with variables is this - go through each column and see if there any nulls. If there are nulls for that particular column, I am going to do one of two possibilities. 1) Based on the significance f the column and amount of missing data, I will either find a way to fill the nulls with using other data or if I perceive that, that column is not important or has too much missing data, I will nuke it. And I am ignoring Survival column in this as thats my dependent variable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.PassengerId.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 669,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 669
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Pclass.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 670,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 670
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Sex.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 671,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 671
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Age.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 672,
       "text": [
        "(177, 12)"
       ]
      }
     ],
     "prompt_number": 672
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Alright, age is important and easily replaceable by getting the mean. Lets fill in missing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aveAge = df.Age.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 673
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.Age = df.Age.fillna(value=aveAge)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 674
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Age.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 675,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 675
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.SibSp.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 676,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 676
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Parch.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 677,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 677
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Ticket.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 678,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 678
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Fare.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 679,
       "text": [
        "(0, 12)"
       ]
      }
     ],
     "prompt_number": 679
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Cabin.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 680,
       "text": [
        "(687, 12)"
       ]
      }
     ],
     "prompt_number": 680
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###687 missing items is way too much for me to do something other nuking it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.drop(['Cabin'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 681
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Embarked.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 682,
       "text": [
        "(2, 11)"
       ]
      }
     ],
     "prompt_number": 682
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Lets do something about the missing 2 by highest occurred value for Embarked and use that to fill the blank ones.I might visit this again if my AUC sucks..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "uniqueValueCount = Counter(df.Embarked.values)\n",
      "print uniqueValueCount"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({'S': 644, 'C': 168, 'Q': 77, nan: 2})\n"
       ]
      }
     ],
     "prompt_number": 683
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.Embarked = df.Embarked.fillna(value=\"S\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 684
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.Embarked.isnull()].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 685,
       "text": [
        "(0, 11)"
       ]
      }
     ],
     "prompt_number": 685
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in list(df):\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PassengerId\n",
        "Survived\n",
        "Pclass\n",
        "Name\n",
        "Sex\n",
        "Age\n",
        "SibSp\n",
        "Parch\n",
        "Ticket\n",
        "Fare\n",
        "Embarked\n"
       ]
      }
     ],
     "prompt_number": 686
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets get a clean df now.I'm going to create a new dataframe and put only the three variables I'm going to be using into it.\n",
      "###I am going to have to ignore PassengerId, Ticket and Name in this clean stuff\n",
      "X = pd.DataFrame()\n",
      "X['survived'] = df['Survived']\n",
      "X['pclass'] = df['Pclass']\n",
      "X['sex'] = df['Sex']\n",
      "X['age'] = df['Age']\n",
      "X['sibsp'] = df['SibSp']\n",
      "X['parch'] = df['Parch']\n",
      "X['fare'] = df['Fare']\n",
      "X['embarked'] = df['Embarked']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 687
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#survived will be my dependent variable, y.   I'll assign it to y and remove it from X\n",
      "y = X['survived']\n",
      "X = X.drop(['survived'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 688
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(X.sex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>female</th>\n",
        "      <th>male</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>861</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>862</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>863</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>864</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>865</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>866</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>867</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>868</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>869</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>870</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>871</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>872</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>873</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>874</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>875</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>876</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>877</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>878</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>879</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>880</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>881</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>882</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>883</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>884</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>885</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>886</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>887</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>888</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>889</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>890</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>891 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 689,
       "text": [
        "     female  male\n",
        "0         0     1\n",
        "1         1     0\n",
        "2         1     0\n",
        "3         1     0\n",
        "4         0     1\n",
        "5         0     1\n",
        "6         0     1\n",
        "7         0     1\n",
        "8         1     0\n",
        "9         1     0\n",
        "10        1     0\n",
        "11        1     0\n",
        "12        0     1\n",
        "13        0     1\n",
        "14        1     0\n",
        "15        1     0\n",
        "16        0     1\n",
        "17        0     1\n",
        "18        1     0\n",
        "19        1     0\n",
        "20        0     1\n",
        "21        0     1\n",
        "22        1     0\n",
        "23        0     1\n",
        "24        1     0\n",
        "25        1     0\n",
        "26        0     1\n",
        "27        0     1\n",
        "28        1     0\n",
        "29        0     1\n",
        "..      ...   ...\n",
        "861       0     1\n",
        "862       1     0\n",
        "863       1     0\n",
        "864       0     1\n",
        "865       1     0\n",
        "866       1     0\n",
        "867       0     1\n",
        "868       0     1\n",
        "869       0     1\n",
        "870       0     1\n",
        "871       1     0\n",
        "872       0     1\n",
        "873       0     1\n",
        "874       1     0\n",
        "875       1     0\n",
        "876       0     1\n",
        "877       0     1\n",
        "878       0     1\n",
        "879       1     0\n",
        "880       1     0\n",
        "881       0     1\n",
        "882       1     0\n",
        "883       0     1\n",
        "884       0     1\n",
        "885       1     0\n",
        "886       0     1\n",
        "887       1     0\n",
        "888       1     0\n",
        "889       0     1\n",
        "890       0     1\n",
        "\n",
        "[891 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 689
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Lets One Hot encode our variables. Fancy term for binary representation of the active state :-)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X['sex'] = pd.get_dummies(X.sex)['female']\n",
      "X.fare = pd.qcut(X.fare,q=5)\n",
      "my_fare = pd.get_dummies(X['fare'], prefix='fare')\n",
      "my_fare.columns = ['fare_1', 'fare_2', 'fare_3', 'fare_4', 'fare_5']\n",
      "my_pclass = pd.get_dummies(X['pclass'], prefix='pclass')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 690
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X[['sex','sibsp', 'age', 'parch']].join(my_fare.ix[:, 'fare_3':]).join(my_pclass.ix[:, 'pclass_mine':])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 691
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     sex  sibsp        age  parch  fare_3  fare_4  fare_5\n",
        "0      0      1  22.000000      0       0       0       1\n",
        "1      1      1  38.000000      0       1       0       0\n",
        "2      1      0  26.000000      0       0       1       0\n",
        "3      1      1  35.000000      0       1       0       0\n",
        "4      0      0  35.000000      0       0       1       0\n",
        "5      0      0  29.699118      0       0       1       0\n",
        "6      0      0  54.000000      0       1       0       0\n",
        "7      0      3   2.000000      1       0       0       0\n",
        "8      1      0  27.000000      2       0       0       0\n",
        "9      1      1  14.000000      0       0       0       0\n",
        "10     1      1   4.000000      1       0       0       0\n",
        "11     1      0  58.000000      0       0       0       0\n",
        "12     0      0  20.000000      0       0       1       0\n",
        "13     0      1  39.000000      5       0       0       0\n",
        "14     1      0  14.000000      0       0       0       1\n",
        "15     1      0  55.000000      0       0       0       0\n",
        "16     0      4   2.000000      1       0       0       0\n",
        "17     0      0  29.699118      0       0       0       0\n",
        "18     1      1  31.000000      0       0       0       0\n",
        "19     1      0  29.699118      0       0       0       1\n",
        "20     0      0  35.000000      0       0       0       0\n",
        "21     0      0  34.000000      0       0       0       0\n",
        "22     1      0  15.000000      0       0       1       0\n",
        "23     0      0  28.000000      0       0       0       0\n",
        "24     1      3   8.000000      1       0       0       0\n",
        "25     1      1  38.000000      5       0       0       0\n",
        "26     0      0  29.699118      0       0       0       1\n",
        "27     0      3  19.000000      2       1       0       0\n",
        "28     1      0  29.699118      0       0       1       0\n",
        "29     0      0  29.699118      0       0       1       0\n",
        "..   ...    ...        ...    ...     ...     ...     ...\n",
        "861    0      1  21.000000      0       0       0       0\n",
        "862    1      0  48.000000      0       0       0       0\n",
        "863    1      8  29.699118      2       1       0       0\n",
        "864    0      0  24.000000      0       0       0       0\n",
        "865    1      0  42.000000      0       0       0       0\n",
        "866    1      1  27.000000      0       0       0       0\n",
        "867    0      0  31.000000      0       1       0       0\n",
        "868    0      0  29.699118      0       0       1       0\n",
        "869    0      1   4.000000      1       0       0       0\n",
        "870    0      0  26.000000      0       0       1       0\n",
        "871    1      1  47.000000      1       1       0       0\n",
        "872    0      0  33.000000      0       0       0       1\n",
        "873    0      0  47.000000      0       0       1       0\n",
        "874    1      1  28.000000      0       0       0       0\n",
        "875    1      0  15.000000      0       0       0       1\n",
        "876    0      0  20.000000      0       0       1       0\n",
        "877    0      0  19.000000      0       0       1       0\n",
        "878    0      0  29.699118      0       0       1       0\n",
        "879    1      0  56.000000      1       1       0       0\n",
        "880    1      0  25.000000      1       0       0       0\n",
        "881    0      0  33.000000      0       0       1       0\n",
        "882    1      0  22.000000      0       0       0       0\n",
        "883    0      0  28.000000      0       0       1       0\n",
        "884    0      0  25.000000      0       0       0       1\n",
        "885    1      0  39.000000      5       0       0       0\n",
        "886    0      0  27.000000      0       0       0       0\n",
        "887    1      0  19.000000      0       0       0       0\n",
        "888    1      1  29.699118      2       0       0       0\n",
        "889    0      0  26.000000      0       0       0       0\n",
        "890    0      0  32.000000      0       0       0       1\n",
        "\n",
        "[891 rows x 7 columns]\n"
       ]
      }
     ],
     "prompt_number": 692
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remember to scale our features, as with linear regression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "X= scaler.fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 693
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build test and training sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.07, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 694
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model Creation\n",
      "At this point I have a test and train set defined.  I will use train to train my model and test to see how accurate the model is.\n",
      "\n",
      "There's one problem with that though.   Lets say my model is right 70% of the time.   Is that good?  Maybe?   \n",
      "\n",
      "I'm going to build a simple 'base rate' model to compare my logistic model to, so we can see if our logistic model is useful or not.  \n",
      "\n",
      "Then, I'll build my logistic model.\n",
      "\n",
      "\n",
      "####Base Rate Model\n",
      "For my baserate model, I'm going to predict that everyone dies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This function looks for females in the test set and returns 1, survived, otherwise it returns 0\n",
      "def base_rate_model(X):\n",
      "    y = np.zeros(X.shape[0])\n",
      "    return y    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 695
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how accurate is my base rate model?\n",
      "y_base_rate = base_rate_model(X_test)\n",
      "from sklearn.metrics import accuracy_score\n",
      "print \"Base rate accuracy is %2.2f\" % accuracy_score(y_test, y_base_rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Base rate accuracy is 0.57\n"
       ]
      }
     ],
     "prompt_number": 696
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, our base model is 59% correct, lets see if logistic can beat it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "model = LogisticRegression(penalty='l2', C=0.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 697
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 698,
       "text": [
        "LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 698
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Logistic accuracy is %2.2f\" % accuracy_score(y_test,model.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic accuracy is 0.84\n"
       ]
      }
     ],
     "prompt_number": 699
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model Comparison\n",
      "\n",
      "Our base model wasn't very good, but it looked better than it was because of class imbalance.  There are many more 0s than 1s in our dataset, so if we just guess 0 we can 'cheat.'\n",
      "\n",
      "A better metric for binary classifer comparisons is AUC or area under the curve. \n",
      "\n",
      "Closely related is [precision and recall](http://scikit-learn.org/stable/auto_examples/plot_precision_recall.html).\n",
      "\n",
      "Precision is the fraction of correctly identified examples of a class (ratio of true positives to all positives).\n",
      "\n",
      "Recall is the fraction of observastions classified in that class that was correctly classified.  \n",
      "\n",
      "Think of fishing with a net for tuna.   \n",
      "*  If our net is very precise, and has high recall it will catch any and all tuna and ONLY tuna.\n",
      "*  If our net is very precise, but has low recall then we might catch one tuna, but most will escape.\n",
      "*  If our net is low precision, but has high recall, then we might catch tuna, but also any other fish around\n",
      "*  If our net is low precision, and low recall, then we should probably give up fishing.   \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 700
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"---Base Model---\"\n",
      "#base rate AUC\n",
      "base_roc_auc = roc_auc_score(y_test, base_rate_model(X_test))\n",
      "print \"Base Rate AUC = %2.2f\" % base_roc_auc\n",
      "print classification_report(y_test,base_rate_model(X_test) )\n",
      "print \"\\n\\n---Logistic Model---\"\n",
      "#logistic AUC\n",
      "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
      "print \"Logistic AUC = %2.2f\" % logit_roc_auc\n",
      "print classification_report(y_test, model.predict(X_test) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---Base Model---\n",
        "Base Rate AUC = 0.50\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.57      1.00      0.73        36\n",
        "          1       0.00      0.00      0.00        27\n",
        "\n",
        "avg / total       0.33      0.57      0.42        63\n",
        "\n",
        "\n",
        "\n",
        "---Logistic Model---\n",
        "Logistic AUC = 0.83\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.82      0.92      0.87        36\n",
        "          1       0.87      0.74      0.80        27\n",
        "\n",
        "avg / total       0.84      0.84      0.84        63\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 701
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 702
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure()\n",
      "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % logit_roc_auc)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic example')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxpgsLGMwxhiTxf8DYdjQ9+QrF5cAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x173a0978>"
       ]
      }
     ],
     "prompt_number": 703
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 703
    }
   ],
   "metadata": {}
  }
 ]
}